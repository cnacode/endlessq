"use strict";(self.webpackChunkendlessq=self.webpackChunkendlessq||[]).push([[8581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"quests","href":"/endlessq/docs/quests","docId":"quests","unlisted":false},{"type":"category","label":"Vision Transformers (ViT)","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Model Structure","href":"/endlessq/docs/vision-transformer/model-structure","docId":"vision-transformer/model-structure","unlisted":false},{"type":"link","label":"The Main Class","href":"/endlessq/docs/vision-transformer/vit-model","docId":"vision-transformer/vit-model","unlisted":false},{"type":"link","label":"ViT for Masked Image Modeling","href":"/endlessq/docs/vision-transformer/masked-modeling","docId":"vision-transformer/masked-modeling","unlisted":false},{"type":"link","label":"Pooling and Classification Heads","href":"/endlessq/docs/vision-transformer/pooling-classification-head","docId":"vision-transformer/pooling-classification-head","unlisted":false},{"type":"category","label":"ViT Sub-Modules","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"ViTSelfAttention and ViTAttention","href":"/endlessq/docs/vision-transformer/sub-modules/sub-modules-attention","docId":"vision-transformer/sub-modules/sub-modules-attention","unlisted":false},{"type":"link","label":"ViTEmbeddings","href":"/endlessq/docs/vision-transformer/sub-modules/sub-modules-embeddings","docId":"vision-transformer/sub-modules/sub-modules-embeddings","unlisted":false},{"type":"link","label":"ViTEncoder and ViTLayer","href":"/endlessq/docs/vision-transformer/sub-modules/sub-modules-encoder","docId":"vision-transformer/sub-modules/sub-modules-encoder","unlisted":false},{"type":"link","label":"ViTIntermediate and ViTOutput","href":"/endlessq/docs/vision-transformer/sub-modules/sub-modules-output","docId":"vision-transformer/sub-modules/sub-modules-output","unlisted":false}],"href":"/endlessq/docs/vision-transformer/sub-modules/"},{"type":"link","label":"Weight Initialization and Model Utilities","href":"/endlessq/docs/vision-transformer/utils","docId":"vision-transformer/utils","unlisted":false}],"href":"/endlessq/docs/vision-transformer/"}]},"docs":{"quests":{"id":"quests","title":"quests","description":"Here be Quests...","sidebar":"tutorialSidebar"},"vision-transformer/masked-modeling":{"id":"vision-transformer/masked-modeling","title":"ViT for Masked Image Modeling","description":"This class is designed for the task of masked image modeling, it reconstructs masked portions of images, which is a form of self-supervised learning where the model learns to predict the parts of the image that have been masked.","sidebar":"tutorialSidebar"},"vision-transformer/model-structure":{"id":"vision-transformer/model-structure","title":"Model Structure","description":"","sidebar":"tutorialSidebar"},"vision-transformer/pooling-classification-head":{"id":"vision-transformer/pooling-classification-head","title":"Pooling and Classification Heads","description":"This detailed breakdown explains how the ViTPooler and ViTForImageClassification classes are focusing on summarizing the information from the transformer and applying it to image classification tasks.","sidebar":"tutorialSidebar"},"vision-transformer/sub-modules/sub-modules":{"id":"vision-transformer/sub-modules/sub-modules","title":"ViT Sub-Modules","description":"- Each of the following sections will describe the role and functionality of individual submodules in the ViT model. We will progress in a hierarchical manner, explaining how each part contributes to the overall functionality.","sidebar":"tutorialSidebar"},"vision-transformer/sub-modules/sub-modules-attention":{"id":"vision-transformer/sub-modules/sub-modules-attention","title":"ViTSelfAttention and ViTAttention","description":"Dimentionality Check","sidebar":"tutorialSidebar"},"vision-transformer/sub-modules/sub-modules-embeddings":{"id":"vision-transformer/sub-modules/sub-modules-embeddings","title":"ViTEmbeddings","description":"The class handles the embedding of image patches and adds necessary tokens and positional information, setting the stage for the operations that follow in the ViT architecture.","sidebar":"tutorialSidebar"},"vision-transformer/sub-modules/sub-modules-encoder":{"id":"vision-transformer/sub-modules/sub-modules-encoder","title":"ViTEncoder and ViTLayer","description":"Lets examine how the encoder processes input hidden states layer-by-layer, each adding to the model\'s understanding of the image. This sequential processing, enriched by the self-attention mechanism, allows the model to integrate information across the entire image, distinguishing Vision Transformers from architectures that focus on local image features.","sidebar":"tutorialSidebar"},"vision-transformer/sub-modules/sub-modules-output":{"id":"vision-transformer/sub-modules/sub-modules-output","title":"ViTIntermediate and ViTOutput","description":"ViTIntermediate and ViTOutput together form the feed-forward part of the Transformer\'s encoder block in the Vision Transformer model, with ViTIntermediate serving as the expansion layer and ViTOutput applying a projection back to the original dimension and making a residual connection.","sidebar":"tutorialSidebar"},"vision-transformer/utils":{"id":"vision-transformer/utils","title":"Weight Initialization and Model Utilities","description":"The ViTPreTrainedModel class and these utility functions play crucial roles in setting up a common framework for all Vision Transformer models. They handle important aspects like weight initialization, configuration management, logging, and documentation, streamlining the process of developing and using different ViT models within the Transformers library.","sidebar":"tutorialSidebar"},"vision-transformer/vision-transformer":{"id":"vision-transformer/vision-transformer","title":"Vision Transformers (ViT)","description":"In this quest, we dive deep into the sourcecode of the transformers package, specifically into the file carrying Vision Transformers (ViT) model. But first, a little bit about the Vision Transformer.","sidebar":"tutorialSidebar"},"vision-transformer/vit-model":{"id":"vision-transformer/vit-model","title":"The Main Class","description":"","sidebar":"tutorialSidebar"}}}')}}]);