"use strict";(self.webpackChunkendlessq=self.webpackChunkendlessq||[]).push([[4466],{6817:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>c,frontMatter:()=>o,metadata:()=>a,toc:()=>l});var i=t(4848),s=t(8453);const o={},r="ViTSelfAttention and ViTAttention",a={id:"vision-transformer/sub-modules/sub-modules-attention",title:"ViTSelfAttention and ViTAttention",description:"Dimentionality Check",source:"@site/docs/vision-transformer/sub-modules/sub-modules-attention.md",sourceDirName:"vision-transformer/sub-modules",slug:"/vision-transformer/sub-modules/sub-modules-attention",permalink:"/endlessq/docs/vision-transformer/sub-modules/sub-modules-attention",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"ViT Sub-Modules",permalink:"/endlessq/docs/vision-transformer/sub-modules/"},next:{title:"ViTEmbeddings",permalink:"/endlessq/docs/vision-transformer/sub-modules/sub-modules-embeddings"}},d={},l=[{value:"Dimentionality Check",id:"dimentionality-check",level:2},{value:"Attention Heads Configuration",id:"attention-heads-configuration",level:2},{value:"Linear Layers for Query, Key, Value",id:"linear-layers-for-query-key-value",level:2},{value:"Dropout Layer",id:"dropout-layer",level:2},{value:"transpose_for_scores Method",id:"transpose_for_scores-method",level:2},{value:"Forward Method",id:"forward-method",level:2},{value:"Constructor",id:"constructor",level:2},{value:"Self-Attention and Output Layers",id:"self-attention-and-output-layers",level:2},{value:"Pruned Heads Initialization",id:"pruned-heads-initialization",level:2},{value:"Prune Heads Method",id:"prune-heads-method",level:2},{value:"Forward Method",id:"forward-method-1",level:2}];function h(e){const n={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"vitselfattention-and-vitattention",children:"ViTSelfAttention and ViTAttention"}),"\n",(0,i.jsxs)(n.h1,{id:"vitselfattention-class-exploration",children:[(0,i.jsx)(n.code,{children:"ViTSelfAttention"})," Class Exploration"]}),"\n",(0,i.jsx)(n.h2,{id:"dimentionality-check",children:"Dimentionality Check"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, "embedding_size"):\n    raise ValueError(...)\n'})}),"\n",(0,i.jsx)(n.p,{children:"This checks if the hidden size is divisible by the number of attention heads. It ensures that the model's dimensions align correctly for multi-head attention."}),"\n",(0,i.jsx)(n.h2,{id:"attention-heads-configuration",children:"Attention Heads Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"self.num_attention_heads = config.num_attention_heads\nself.attention_head_size = int(config.hidden_size / config.num_attention_heads)\nself.all_head_size = self.num_attention_heads * self.attention_head_size\n"})}),"\n",(0,i.jsx)(n.p,{children:"These lines set up the configuration for the attention heads. It calculates the size of each attention head and the total size of all heads combined."}),"\n",(0,i.jsx)(n.h2,{id:"linear-layers-for-query-key-value",children:"Linear Layers for Query, Key, Value"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"self.query = nn.Linear(config.hidden_size, self.all_head_size, bias=config.qkv_bias)\nself.key = nn.Linear(config.hidden_size, self.all_head_size, bias=config.qkv_bias)\nself.value = nn.Linear(config.hidden_size, self.all_head_size, bias=config.qkv_bias)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Three linear layers are defined for transforming the input into query, key, and value vectors. These are essential components of the self-attention mechanism."}),"\n",(0,i.jsx)(n.h2,{id:"dropout-layer",children:"Dropout Layer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n"})}),"\n",(0,i.jsx)(n.p,{children:"A dropout layer is added to regularize the attention weights and prevent over-fitting."}),"\n",(0,i.jsx)(n.h2,{id:"transpose_for_scores-method",children:"transpose_for_scores Method"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n    ...\n"})}),"\n",(0,i.jsx)(n.p,{children:"This method reshapes and transposes the input tensor for the multi-head attention operation, preparing it for matrix multiplication."}),"\n",(0,i.jsx)(n.h2,{id:"forward-method",children:"Forward Method"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def forward(\n    self, hidden_states, head_mask: Optional[torch.Tensor] = None, output_attentions: bool = False\n) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"forward"})," method defines the computation performed at every call. It computes the self-attention using the input ",(0,i.jsx)(n.code,{children:"hidden_states"}),"."]}),"\n",(0,i.jsxs)(n.h1,{id:"vitattention-class-exploration",children:[(0,i.jsx)(n.code,{children:"ViTAttention"})," Class Exploration"]}),"\n",(0,i.jsx)(n.h2,{id:"constructor",children:"Constructor"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def __init__(self, config: ViTConfig) -> None:\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The constructor takes ",(0,i.jsx)(n.code,{children:"ViTConfig"})," as an argument, similar to ",(0,i.jsx)(n.code,{children:"ViTSelfAttention"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"self-attention-and-output-layers",children:"Self-Attention and Output Layers"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"self.attention = ViTSelfAttention(config)\nself.output = ViTSelfOutput(config)\n"})}),"\n",(0,i.jsxs)(n.p,{children:["It initializes a ",(0,i.jsx)(n.code,{children:"ViTSelfAttention"})," instance for computing self-attention and a ",(0,i.jsx)(n.code,{children:"ViTSelfOutput"})," instance for processing the output of the self-attention layer."]}),"\n",(0,i.jsx)(n.h2,{id:"pruned-heads-initialization",children:"Pruned Heads Initialization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"self.pruned_heads = set()\n"})}),"\n",(0,i.jsx)(n.p,{children:"Initializes an empty set to keep track of any attention heads that are pruned (removed) from the model for efficiency or experimentation."}),"\n",(0,i.jsx)(n.h2,{id:"prune-heads-method",children:"Prune Heads Method"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def prune_heads(self, heads: Set[int]) -> None:\n    ...\n"})}),"\n",(0,i.jsx)(n.p,{children:"This method allows for the removal of specific attention heads, which can be useful for model optimization and interpretability studies."}),"\n",(0,i.jsx)(n.h2,{id:"forward-method-1",children:"Forward Method"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def forward(\n    self,\n    hidden_states: torch.Tensor,\n    head_mask: Optional[torch.Tensor] = None,\n    output_attentions: bool = False,\n) -> Union[Tuple[torch.Tensor, torch.Tensor], Tuple[torch.Tensor]]:\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"forward"})," method in ",(0,i.jsx)(n.code,{children:"ViTAttention"})," calls the ",(0,i.jsx)(n.code,{children:"forward"})," method of ",(0,i.jsx)(n.code,{children:"ViTSelfAttention"})," and then processes its output further"]})]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);