"use strict";(self.webpackChunkendlessq=self.webpackChunkendlessq||[]).push([[3127],{8243:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>a,toc:()=>c});var s=n(4848),r=n(8453);const t={},o="Vision Transformers (ViT)",a={id:"vision-transformer/vision-transformer",title:"Vision Transformers (ViT)",description:"In this quest, we dive deep into the sourcecode of the transformers package, specifically into the file carrying Vision Transformers (ViT) model. But first, a little bit about the Vision Transformer.",source:"@site/docs/vision-transformer/vision-transformer.md",sourceDirName:"vision-transformer",slug:"/vision-transformer/",permalink:"/endlessq/docs/vision-transformer/",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"quests",permalink:"/endlessq/docs/quests"},next:{title:"Model Structure",permalink:"/endlessq/docs/vision-transformer/model-structure"}},l={},c=[{value:"Why Vision Transformers are Important",id:"why-vision-transformers-are-important",level:2}];function d(e){const i={h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h1,{id:"vision-transformers-vit",children:"Vision Transformers (ViT)"}),"\n",(0,s.jsx)(i.p,{children:"In this quest, we dive deep into the sourcecode of the transformers package, specifically into the file carrying Vision Transformers (ViT) model. But first, a little bit about the Vision Transformer."}),"\n",(0,s.jsx)(i.p,{children:"Historically, Convolutional Neural Networks (CNNs) dominated the scene, renowned for their proficiency in handling image data. However, the emergence of ViT introduces a new approach, extending the transformative power of transformers, previously acclaimed in natural language processing, to the visual domain."}),"\n",(0,s.jsx)(i.p,{children:"The introduction of ViT had broad implications for deep learning. It challenged the long-held dominance of CNNs in image-related tasks, suggesting a potential shift towards more flexible architectures like transformers. Its success also opens avenues for cross-pollination between NLP and computer vision, providing insights into how techniques developed in one domain can be adapted for another."}),"\n",(0,s.jsx)(i.p,{children:"Transformers revolutionized natural language processing by efficiently handling sequences of data and capturing long-range dependencies."}),"\n",(0,s.jsx)(i.p,{children:"ViT adapts this concept to images. In ViT, an image is split into a sequence of fixed-size patches, akin to words in a sentence. These patches are then linearly embedded and processed through a series of transformer blocks, each consisting of multi-head self-attention and feedforward neural networks."}),"\n",(0,s.jsx)(i.p,{children:"ViT\u2019s novelty lies in its departure from the inductive biases inherent in CNNs - locality and translation invariance. Instead, it relies on self-attention mechanisms to weigh the importance of different patches of an image, enabling it to dynamically focus on relevant parts of the image irrespective of their spatial location."}),"\n",(0,s.jsx)(i.p,{children:"This ability to capture global dependencies across the image sets ViT apart and contributes to its impressive performance on various image recognition tasks."}),"\n",(0,s.jsx)(i.h2,{id:"why-vision-transformers-are-important",children:"Why Vision Transformers are Important"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Performance"}),": ViT has achieved state-of-the-art results on numerous benchmark datasets, outperforming traditional CNNs in many cases."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Scalability"}),": ViT's architecture scales well with the increase in data and compute resources, often becoming more effective as model size grows."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Interpretability"}),": The self-attention mechanism in ViT provides a level of interpretability. It allows us to visualize and understand which parts of the image the model focuses on, making it a valuable tool for tasks requiring explainability."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Innovation"}),": ViT paves the way for new research directions, inspiring novel architectures and hybrid models that combine the strengths of CNNs and transformers."]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);