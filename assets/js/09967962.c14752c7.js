"use strict";(self.webpackChunkendlessq=self.webpackChunkendlessq||[]).push([[5227],{7:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>r,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>d});var s=n(4848),t=n(8453);const a={},l="Pooling and Classification Heads",o={id:"vision-transformer/pooling-classification-head",title:"Pooling and Classification Heads",description:"This detailed breakdown explains how the ViTPooler and ViTForImageClassification classes are focusing on summarizing the information from the transformer and applying it to image classification tasks.",source:"@site/docs/vision-transformer/pooling-classification-head.md",sourceDirName:"vision-transformer",slug:"/vision-transformer/pooling-classification-head",permalink:"/endlessq/docs/vision-transformer/pooling-classification-head",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"ViT for Masked Image Modeling",permalink:"/endlessq/docs/vision-transformer/masked-modeling"},next:{title:"ViT Sub-Modules",permalink:"/endlessq/docs/vision-transformer/sub-modules/"}},r={},d=[{value:"Linear Layer Initialization",id:"linear-layer-initialization",level:2},{value:"Activation Function",id:"activation-function",level:2},{value:"Forward Method",id:"forward-method",level:2},{value:"Extracting the First Token&#39;s State",id:"extracting-the-first-tokens-state",level:2},{value:"Applying Dense Layer and Activation",id:"applying-dense-layer-and-activation",level:2},{value:"Number of Labels",id:"number-of-labels",level:2},{value:"Initializing ViTModel",id:"initializing-vitmodel",level:2},{value:"Classifier Head",id:"classifier-head",level:2},{value:"Weights Initialization and Final Processing",id:"weights-initialization-and-final-processing",level:2},{value:"Forward Method",id:"forward-method-1",level:2},{value:"Processing Pixel Values through ViTModel",id:"processing-pixel-values-through-vitmodel",level:2},{value:"Getting Sequence Output",id:"getting-sequence-output",level:2},{value:"Applying Classifier Head",id:"applying-classifier-head",level:2},{value:"Computing Loss (if Labels Provided)",id:"computing-loss-if-labels-provided",level:2},{value:"Returning the Output",id:"returning-the-output",level:2}];function c(e){const i={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.h1,{id:"pooling-and-classification-heads",children:"Pooling and Classification Heads"}),"\n",(0,s.jsxs)(i.p,{children:["This detailed breakdown explains how the ",(0,s.jsx)(i.code,{children:"ViTPooler"})," and ",(0,s.jsx)(i.code,{children:"ViTForImageClassification"})," classes are focusing on summarizing the information from the transformer and applying it to image classification tasks."]}),"\n",(0,s.jsxs)(i.h1,{id:"vitpooler-class-exploration",children:[(0,s.jsx)(i.code,{children:"ViTPooler"})," Class Exploration"]}),"\n",(0,s.jsx)(i.h2,{id:"linear-layer-initialization",children:"Linear Layer Initialization"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n"})}),"\n",(0,s.jsxs)(i.p,{children:["Initializes a linear layer (",(0,s.jsx)(i.code,{children:"self.dense"}),") that projects the hidden states to the same dimension. This layer is applied to the [CLS] token's representation for classification tasks."]}),"\n",(0,s.jsx)(i.h2,{id:"activation-function",children:"Activation Function"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"self.activation = nn.Tanh()\n"})}),"\n",(0,s.jsx)(i.p,{children:"A hyperbolic tangent (Tanh) activation function is used after the linear layer."}),"\n",(0,s.jsx)(i.h2,{id:"forward-method",children:"Forward Method"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"def forward(self, hidden_states):\n    ...\n"})}),"\n",(0,s.jsxs)(i.p,{children:["The ",(0,s.jsx)(i.code,{children:"forward"})," method defines how the pooling layer processes the input hidden states."]}),"\n",(0,s.jsx)(i.h2,{id:"extracting-the-first-tokens-state",children:"Extracting the First Token's State"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"first_token_tensor = hidden_states[:, 0]\n"})}),"\n",(0,s.jsx)(i.p,{children:"This line extracts the hidden state corresponding to the [CLS] token, which is the first token in the sequence."}),"\n",(0,s.jsx)(i.h2,{id:"applying-dense-layer-and-activation",children:"Applying Dense Layer and Activation"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"pooled_output = self.dense(first_token_tensor)\npooled_output = self.activation(pooled_output)\n"})}),"\n",(0,s.jsxs)(i.p,{children:["The extracted [CLS] token's hidden state is passed through the dense layer and Tanh activation function. The result (",(0,s.jsx)(i.code,{children:"pooled_output"}),") serves as a summarized representation of the entire sequence for classification tasks."]}),"\n",(0,s.jsxs)(i.p,{children:["#",(0,s.jsx)(i.code,{children:"ViTForImageClassification"})," Class Exploration"]}),"\n",(0,s.jsx)(i.h2,{id:"number-of-labels",children:"Number of Labels"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"self.num_labels = config.num_labels\n"})}),"\n",(0,s.jsx)(i.p,{children:"This line sets the number of labels for the classification task based on the provided configuration."}),"\n",(0,s.jsx)(i.h2,{id:"initializing-vitmodel",children:"Initializing ViTModel"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"self.vit = ViTModel(config, add_pooling_layer=False)\n"})}),"\n",(0,s.jsxs)(i.p,{children:["Initializes the ",(0,s.jsx)(i.code,{children:"ViTModel"})," without an additional pooling layer since the pooling is handled separately in ",(0,s.jsx)(i.code,{children:"ViTPooler"}),"."]}),"\n",(0,s.jsx)(i.h2,{id:"classifier-head",children:"Classifier Head"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"self.classifier = nn.Linear(config.hidden_size, config.num_labels) if config.num_labels > 0 else nn.Identity()\n"})}),"\n",(0,s.jsxs)(i.p,{children:["A linear layer is defined as the classifier head, transforming the pooled output to the final output size equal to the number of labels. If ",(0,s.jsx)(i.code,{children:"num_labels"})," is 0, an identity function is used (useful for regression tasks)."]}),"\n",(0,s.jsx)(i.h2,{id:"weights-initialization-and-final-processing",children:"Weights Initialization and Final Processing"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"self.post_init()\n"})}),"\n",(0,s.jsxs)(i.p,{children:["This line calls ",(0,s.jsx)(i.code,{children:"post_init"}),", a method from ",(0,s.jsx)(i.code,{children:"ViTPreTrainedModel"}),", to initialize weights and apply any final model configurations."]}),"\n",(0,s.jsx)(i.h2,{id:"forward-method-1",children:"Forward Method"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"def forward(\n    self,\n    pixel_values: Optional[torch.Tensor] = None,\n    head_mask: Optional[torch.Tensor] = None,\n    labels: Optional[torch.Tensor] = None,\n    output_attentions: Optional[bool] = None,\n    output_hidden_states: Optional[bool] = None,\n    interpolate_pos_encoding: Optional[bool] = None,\n    return_dict: Optional[bool] = None,\n) -> Union[tuple, ImageClassifierOutput]:\n"})}),"\n",(0,s.jsxs)(i.p,{children:["The ",(0,s.jsx)(i.code,{children:"forward"})," method defines the computation performed at every call. It processes input pixel values through the ViT model and classifier for image classification."]}),"\n",(0,s.jsx)(i.h2,{id:"processing-pixel-values-through-vitmodel",children:"Processing Pixel Values through ViTModel"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"outputs = self.vit(\n    pixel_values,\n    head_mask=head_mask,\n    ...\n    return_dict=return_dict,\n)\n"})}),"\n",(0,s.jsxs)(i.p,{children:["This block passes the input pixel values and other optional parameters to the ",(0,s.jsx)(i.code,{children:"ViTModel"}),", obtaining the output sequence."]}),"\n",(0,s.jsx)(i.h2,{id:"getting-sequence-output",children:"Getting Sequence Output"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"sequence_output = outputs[0]\n"})}),"\n",(0,s.jsx)(i.p,{children:"Extracts the sequence output from the ViT model's output."}),"\n",(0,s.jsx)(i.h2,{id:"applying-classifier-head",children:"Applying Classifier Head"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"logits = self.classifier(sequence_output[:, 0, :])\n"})}),"\n",(0,s.jsx)(i.p,{children:"Applies the classifier head to the [CLS] token's output to obtain the final logits."}),"\n",(0,s.jsx)(i.h2,{id:"computing-loss-if-labels-provided",children:"Computing Loss (if Labels Provided)"}),"\n",(0,s.jsx)(i.pre,{children:(0,s.jsx)(i.code,{className:"language-python",children:"if labels is not None:\n    ...\n"})}),"\n",(0,s.jsx)(i.p,{children:"If labels are provided, this block computes the loss using the appropriate loss function based on the problem type (regression, single/multi-label classification)."}),"\n",(0,s.jsx)(i.h2,{id:"returning-the-output",children:"Returning the Output"}),"\n",(0,s.jsx)(i.p,{children:"Returns the computed logits, loss (if applicable), and optionally hidden states and attentions, based on the specified flags."})]})}function h(e={}){const{wrapper:i}={...(0,t.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);