<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-vision-transformer/sub-modules/sub-modules-embeddings" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">ViTEmbeddings | Endless Quests</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://endlessq.com/endlessq/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://endlessq.com/endlessq/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://endlessq.com/endlessq/docs/vision-transformer/sub-modules/sub-modules-embeddings"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ViTEmbeddings | Endless Quests"><meta data-rh="true" name="description" content="The class handles the embedding of image patches and adds necessary tokens and positional information, setting the stage for the operations that follow in the ViT architecture."><meta data-rh="true" property="og:description" content="The class handles the embedding of image patches and adds necessary tokens and positional information, setting the stage for the operations that follow in the ViT architecture."><link data-rh="true" rel="icon" href="/endlessq/img/logo-cropped.svg"><link data-rh="true" rel="canonical" href="https://endlessq.com/endlessq/docs/vision-transformer/sub-modules/sub-modules-embeddings"><link data-rh="true" rel="alternate" href="https://endlessq.com/endlessq/docs/vision-transformer/sub-modules/sub-modules-embeddings" hreflang="en"><link data-rh="true" rel="alternate" href="https://endlessq.com/endlessq/docs/vision-transformer/sub-modules/sub-modules-embeddings" hreflang="x-default"><link rel="stylesheet" href="/endlessq/assets/css/styles.af44cb5a.css">
<script src="/endlessq/assets/js/runtime~main.3a5fdbf3.js" defer="defer"></script>
<script src="/endlessq/assets/js/main.f841d8bb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/endlessq/"><div class="navbar__logo"><img src="/endlessq/img/logo-cropped.svg" alt="Endless Q" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/endlessq/img/logo-cropped.svg" alt="Endless Q" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">EndlessQ</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/endlessq/docs/quests">quests</a><a class="navbar__item navbar__link" href="/endlessq/about-me">about me</a></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_LcQY"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_juUc"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/endlessq/docs/quests">quests</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/endlessq/docs/vision-transformer/">Vision Transformers (ViT)</a><button aria-label="Collapse sidebar category &#x27;Vision Transformers (ViT)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/model-structure">Model Structure</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/vit-model">The Main Class</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/masked-modeling">ViT for Masked Image Modeling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/pooling-classification-head">Pooling and Classification Heads</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/endlessq/docs/vision-transformer/sub-modules/">ViT Sub-Modules</a><button aria-label="Collapse sidebar category &#x27;ViT Sub-Modules&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/sub-modules/sub-modules-attention">ViTSelfAttention and ViTAttention</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/endlessq/docs/vision-transformer/sub-modules/sub-modules-embeddings">ViTEmbeddings</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/sub-modules/sub-modules-encoder">ViTEncoder and ViTLayer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/sub-modules/sub-modules-output">ViTIntermediate and ViTOutput</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/utils">Weight Initialization and Model Utilities</a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_CEj5"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/endlessq/docs/vision-transformer/"><span itemprop="name">Vision Transformers (ViT)</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/endlessq/docs/vision-transformer/sub-modules/"><span itemprop="name">ViT Sub-Modules</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">ViTEmbeddings</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>ViTEmbeddings</h1>
<p>The class handles the embedding of image patches and adds necessary tokens and positional information, setting the stage for the operations that follow in the ViT architecture.
It prepares the input image for subsequent processing stages, ensuring that crucial information about image patches and their positions is effectively encapsulated in the embeddings.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="constructor-and-parameters">Constructor and Parameters:<a href="#constructor-and-parameters" class="hash-link" aria-label="Direct link to Constructor and Parameters:" title="Direct link to Constructor and Parameters:">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">__init__</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> ViTConfig</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> use_mask_token</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">bool</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The constructor of <code>ViTEmbeddings</code> takes two parameters: a configuration object (<code>config</code>), which contains all the necessary settings for the model, and a boolean <code>use_mask_token</code>.</p>
<p>The <code>use_mask_token</code> flag determines whether an additional mask token should be used, which is particularly relevant for tasks like masked image modeling.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cls-token-embedding">CLS Token Embedding<a href="#cls-token-embedding" class="hash-link" aria-label="Direct link to CLS Token Embedding" title="Direct link to CLS Token Embedding">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">cls_token </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Parameter</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">hidden_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Here, a class (CLS) token is created and registered as a parameter of the model. It&#x27;s initialized randomly and will be learned during training. This token is crucial for tasks like image classification, where the representation of this token is used as the overall representation of the image.</p>
<p>It&#x27;s initialized randomly and is fine-tuned during the training process. In tasks like image classification, the final state of the <code>cls_token</code> serves as a representation of the entire image. The model uses this aggregated information to classify the image.</p>
<p>It interacts with all patch embeddings through the self-attention mechanism, aggregating global information from the entire image.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="optional-mask-token">Optional Mask Token:<a href="#optional-mask-token" class="hash-link" aria-label="Direct link to Optional Mask Token:" title="Direct link to Optional Mask Token:">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">mask_token </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Parameter</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">hidden_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> use_mask_token </span><span class="token keyword" style="color:rgb(86, 156, 214)">else</span><span class="token plain"> </span><span class="token boolean">None</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>If <code>use_mask_token</code> is <code>True</code>, a mask token is also initialized. This is an approach inspired by the masked language modeling concept in NLP models like BERT. In masked image modeling:</p>
<p>If this flag is set, certain parts of the input image (specific patches) are intentionally hidden (masked) during the training process, the model initializes a special token – the mask token. This token is used to replace the embeddings of the masked image patches.</p>
<p>Then, during training, the model learns to predict these masked parts, encouraging the development of a deeper, context-driven understanding of the unmasked parts of the image.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="patch-embeddings">Patch Embeddings:<a href="#patch-embeddings" class="hash-link" aria-label="Direct link to Patch Embeddings:" title="Direct link to Patch Embeddings:">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">patch_embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> ViTPatchEmbeddings</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>It essentially projects the flattened patches into a higher-dimensional space (the embedding space). The <code>ViTPatchEmbeddings</code> class is crucial for converting image pixels into a form suitable for processing by the transformer model.</p>
<p><strong>Processing Image Patches</strong>:
It takes raw pixel values of the image and divides the image into fixed-size patches.
Each patch is then flattened and projected into an embedding space, essentially converting a 2D image patch into a 1D vector.</p>
<p><strong>Embedding Projection</strong>:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">projection </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This is implemented using a 2D convolution layer (<code>nn.Conv2d</code>) which acts as a linear projection. This approach is computationally efficient and maintains spatial locality.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="positional-embeddings">Positional Embeddings:<a href="#positional-embeddings" class="hash-link" aria-label="Direct link to Positional Embeddings:" title="Direct link to Positional Embeddings:">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">position_embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Parameter</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> num_patches </span><span class="token operator" style="color:rgb(212, 212, 212)">+</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">hidden_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Positional embeddings are crucial in Transformers as they add information about the position of each patch in the image. These embeddings are learnable parameters and are added to the patch embeddings to provide the model with spatial context.</p>
<p><code>nn.Parameter</code> is a core concept in PyTorch, used to define variables that should be considered as model parameters. Variables wrapped in <code>nn.Parameter</code> are trainable and are adjusted during the back-propagation process. These parameters are part of the computation graph, and PyTorch keeps track of their gradients automatically.</p>
<p><code>torch.randn</code> generates a tensor with elements sampled from a normal distribution (mean = 0, standard deviation = 1).</p>
<p>The first dimension <code>1</code> is for the batch size, assuming a single image (or a batch of images processed as one).
<code>num_patches + 1</code> represents the total number of patches plus one for the [CLS] token.
<code>config.hidden_size</code> defines the size of the embedding vector for each patch.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="dropout-layer">Dropout Layer:<a href="#dropout-layer" class="hash-link" aria-label="Direct link to Dropout Layer:" title="Direct link to Dropout Layer:">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">dropout </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Dropout</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">hidden_dropout_prob</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Dropout is used as a regularization technique to prevent overfitting. The dropout probability is specified in the configuration.</p>
<p>During training, it randomly sets a fraction of the input units to zero at each update step, which helps in breaking up happenstance correlations in the training data.</p>
<p>By preventing complex co-adaptations on the training data, dropout forces the model to learn more robust features that are useful in conjunction with many different random subsets of the other neurons.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="configuration-storage">Configuration Storage:<a href="#configuration-storage" class="hash-link" aria-label="Direct link to Configuration Storage:" title="Direct link to Configuration Storage:">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">config </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> config</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Storing the configuration object within the class allows easy access to model settings throughout the embedding process.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="interpolating-positional-encodings">Interpolating Positional Encodings<a href="#interpolating-positional-encodings" class="hash-link" aria-label="Direct link to Interpolating Positional Encodings" title="Direct link to Interpolating Positional Encodings">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">interpolate_pos_encoding</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> embeddings</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Tensor</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> height</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> width</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Tensor</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This method is a crucial component when dealing with images of various resolutions.
The original positional encodings are trained on a specific image size.
When input images are of different sizes, this method allows for the resizing of these positional encodings to match the new dimensions.
It ensures that the model can handle images of various resolutions, which is particularly important in real-world applications where input image sizes can vary.</p>
<p>When input images are of different sizes than the ones used in training, this function interpolates the positional embeddings to align with the new dimensions. This ensures that the model remains effective and accurate even when applied to images of sizes it wasn&#x27;t explicitly trained on, enhancing its utility in real-world applications where input image sizes can vary significantly.</p>
<p><strong>The Process of Interpolation</strong></p>
<ol>
<li>
<p>Adjusting to New Image Sizes:
The first step involves computing the new dimensions (h0 and w0) for height and width, respectively. These are derived based on the input image&#x27;s size relative to the patch size configured in the model. This step is pivotal as it sets the stage for the rest of the interpolation process.</p>
</li>
<li>
<p>Reshaping and Interpolating Positional Embeddings:
Using bicubic interpolation, a method known for its ability to resize images while maintaining their quality, the positional embeddings are reshaped. This reshaping ensures that the positional information aligns with the new dimensions of the image, preserving the spatial context essential for the model&#x27;s understanding.</p>
</li>
<li>
<p>Maintaining the Relevance of the [CLS] Token:
The [CLS] token (for classification tasks) is concatenated with these adjusted positional embeddings. This ensures that despite the change in image size, the [CLS] token continues to effectively represent the whole image. The model thereby maintains its capability to use this token for tasks like image classification, regardless of image resolution.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="forward-pass">Forward Pass<a href="#forward-pass" class="hash-link" aria-label="Direct link to Forward Pass" title="Direct link to Forward Pass">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">forward</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> pixel_values</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Tensor</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> bool_masked_pos</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token plain">torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">BoolTensor</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> interpolate_pos_encoding</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">bool</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token operator" style="color:rgb(212, 212, 212)">&gt;</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Tensor</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The forward method is where the actual embedding process happens for a given input.</p>
<p>the process begins with extracting the shape of the input pixel values, identifying the batch size, number of channels, height, and width.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">batch_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> num_channels</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> height</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> width </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> pixel_values</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">shape</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="extracting-embeddings">Extracting Embeddings:<a href="#extracting-embeddings" class="hash-link" aria-label="Direct link to Extracting Embeddings:" title="Direct link to Extracting Embeddings:">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">patch_embeddings</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">pixel_values</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> interpolate_pos_encoding</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">interpolate_pos_encoding</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The forward method calls <code>self.patch_embeddings</code> to convert the input pixel values into patch embeddings. These embeddings are essentially flattened, linear projections of the image patches.</p>
<p>If interpolate_pos_encoding is set to True, this step also adjusts the positional encodings for different image resolutions.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applying-mask-if-present">Applying Mask (If Present):<a href="#applying-mask-if-present" class="hash-link" aria-label="Direct link to Applying Mask (If Present):" title="Direct link to Applying Mask (If Present):">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> bool_masked_pos </span><span class="token keyword" style="color:rgb(86, 156, 214)">is</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(86, 156, 214)">not</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    seq_length </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> embeddings</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    mask_tokens </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">mask_token</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">expand</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">batch_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> seq_length</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token comment" style="color:rgb(106, 153, 85)"># replace the masked visual tokens by mask_tokens</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    mask </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> bool_masked_pos</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">unsqueeze</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">type_as</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">mask_tokens</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">*</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token number" style="color:rgb(181, 206, 168)">1.0</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token plain"> mask</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">+</span><span class="token plain"> mask_tokens </span><span class="token operator" style="color:rgb(212, 212, 212)">*</span><span class="token plain"> mask</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>If <code>bool_masked_pos</code> is provided, which indicates masked positions for masked image modeling, the method applies these masks. It does so by replacing the embeddings at the masked positions with the mask token&#x27;s embeddings.</p>
<p>This process is critical for tasks like self-supervised learning where parts of the input are intentionally hidden during training.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="adding-the-cls-token">Adding the [CLS] Token:<a href="#adding-the-cls-token" class="hash-link" aria-label="Direct link to Adding the [CLS] Token:" title="Direct link to Adding the [CLS] Token:">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">cls_tokens </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">cls_token</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">expand</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">batch_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">-</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">cls_tokens</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> embeddings</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> dim</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token number" style="color:rgb(181, 206, 168)">1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The [CLS] token&#x27;s embedding is then added to the sequence of patch embeddings. It&#x27;s included at the beginning. This token plays an important role in tasks like classification, where its final state represents the aggregate understanding of the entire image.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="positional-encoding-addition">Positional Encoding Addition:<a href="#positional-encoding-addition" class="hash-link" aria-label="Direct link to Positional Encoding Addition:" title="Direct link to Positional Encoding Addition:">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">if</span><span class="token plain"> interpolate_pos_encoding</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">interpolate_pos_encoding</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">embeddings</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> height</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> width</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">else</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">position_embeddings</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Next, either the original or interpolated positional embeddings (based on the <code>interpolate_pos_encoding</code> flag) are added to these embeddings, infusing them with positional context.</p>
<p>Depending on whether interpolation is active (for varying image resolutions), this adds either the original or interpolated positional encodings to provide spatial context to the embeddings.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applying-dropout">Applying Dropout:<a href="#applying-dropout" class="hash-link" aria-label="Direct link to Applying Dropout:" title="Direct link to Applying Dropout:">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">embeddings </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">dropout</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">embeddings</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Finally, a dropout layer is applied for regularization, helping prevent over-fitting.</p>
<p>This layer helps in regularizing the model, reducing the risk of over-fitting by randomly deactivating a subset of neurons during training.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">return</span><span class="token plain"> embeddings</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>These embeddings, now enriched with CLS tokens, masked token adjustments (if applicable), and positional information, are ready for the subsequent layers of the Vision Transformer model.</p>
<h1>VITPatchEmbeddings</h1>
<p>The <code>ViTPatchEmbeddings</code> class is responsible for converting the raw pixel values of an image into a sequence of patch embeddings. It&#x27;s a crucial component of the Vision Transformer model, as it prepares the input image for subsequent processing by the transformer layers.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">image_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> patch_size </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">image_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">patch_size</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">num_channels</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> hidden_size </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">num_channels</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">hidden_size</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>First, the dimensions of the image and patches, the number of channels in the input images, and the size of the hidden layer are extracted from the configuration.</p>
<p>Then, it processes the image and patch sizes to ensure they are iterables (tuples).</p>
<p>image_size = image_size if isinstance(image_size, collections.abc.Iterable) else (image_size, image_size)
patch_size = patch_size if isinstance(patch_size, collections.abc.Iterable) else (patch_size, patch_size)</p>
<p>This step ensures flexibility in the input dimensions, accommodating both uniform and non-uniform image and patch sizes.</p>
<p>After that, number of patches in each image is then calculated. This is done by dividing the height and width of the image by the height and width of each patch, respectively. This calculation determines how many patches an image will be divided into, based on the image and patch sizes.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">num_patches = (image_size[0] // patch_size[0]) * (image_size[1] // patch_size[1])</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The class then initializes its attributes with these values.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">image_size </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> image_size</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">patch_size </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> patch_size</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">num_channels </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> num_channels</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">num_patches </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> num_patches</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>These attributes hold the essential information about the image dimensions, patch sizes, and number of patches, which are used throughout the patch embedding process.</p>
<p>In the next step, A 2D convolutional layer is set up as the projection mechanism. This layer is responsible for projecting the raw pixel values of the image into a higher-dimensional space, essentially converting the 2D image patches into 1D vectors.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">projection </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">Conv2d</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">num_channels</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> hidden_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> kernel_size</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">patch_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> stride</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">patch_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The convolution layer accomplishes this by applying a linear projection to the image patches. In any convolution layer the kernel essentially slides over the image and multiplies the pixel values in the kernel&#x27;s receptive field by the weights in the kernel.</p>
<p>Here the hidden_size is the number of output channels, if the image only has 1 size then the output will be a 2D tensor, if the image has more than 1 channel then the output will be a 3D tensor.</p>
<p>In other words it takes the pixels and then its kernel will slide over the image and apply a linear transformation to the pixels in the kernel&#x27;s receptive field.</p>
<p>It&#x27;s a computationally efficient approach that maintains spatial locality, ensuring that the model can effectively capture spatial relationships between patches.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/endlessq/docs/vision-transformer/sub-modules/sub-modules-attention"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">ViTSelfAttention and ViTAttention</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/endlessq/docs/vision-transformer/sub-modules/sub-modules-encoder"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">ViTEncoder and ViTLayer</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#constructor-and-parameters" class="table-of-contents__link toc-highlight">Constructor and Parameters:</a></li><li><a href="#cls-token-embedding" class="table-of-contents__link toc-highlight">CLS Token Embedding</a></li><li><a href="#optional-mask-token" class="table-of-contents__link toc-highlight">Optional Mask Token:</a></li><li><a href="#patch-embeddings" class="table-of-contents__link toc-highlight">Patch Embeddings:</a></li><li><a href="#positional-embeddings" class="table-of-contents__link toc-highlight">Positional Embeddings:</a></li><li><a href="#dropout-layer" class="table-of-contents__link toc-highlight">Dropout Layer:</a></li><li><a href="#configuration-storage" class="table-of-contents__link toc-highlight">Configuration Storage:</a></li><li><a href="#interpolating-positional-encodings" class="table-of-contents__link toc-highlight">Interpolating Positional Encodings</a></li><li><a href="#forward-pass" class="table-of-contents__link toc-highlight">Forward Pass</a><ul><li><a href="#extracting-embeddings" class="table-of-contents__link toc-highlight">Extracting Embeddings:</a></li><li><a href="#applying-mask-if-present" class="table-of-contents__link toc-highlight">Applying Mask (If Present):</a></li><li><a href="#adding-the-cls-token" class="table-of-contents__link toc-highlight">Adding the [CLS] Token:</a></li><li><a href="#positional-encoding-addition" class="table-of-contents__link toc-highlight">Positional Encoding Addition:</a></li><li><a href="#applying-dropout" class="table-of-contents__link toc-highlight">Applying Dropout:</a></li></ul></li></ul></div></div></div></div></main></div></div><div>Your screen is too small to view EndlessQ documentation. Please view on a larger device.</div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Sina Montazeri. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>