<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-vision-transformer/model-structure" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.1">
<title data-rh="true">Model Structure | Endless Quests</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://endlessq.com/endlessq/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://endlessq.com/endlessq/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://endlessq.com/endlessq/docs/vision-transformer/model-structure"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Model Structure | Endless Quests"><link data-rh="true" rel="icon" href="/endlessq/img/logo-cropped.svg"><link data-rh="true" rel="canonical" href="https://endlessq.com/endlessq/docs/vision-transformer/model-structure"><link data-rh="true" rel="alternate" href="https://endlessq.com/endlessq/docs/vision-transformer/model-structure" hreflang="en"><link data-rh="true" rel="alternate" href="https://endlessq.com/endlessq/docs/vision-transformer/model-structure" hreflang="x-default"><link rel="stylesheet" href="/endlessq/assets/css/styles.af44cb5a.css">
<script src="/endlessq/assets/js/runtime~main.3a5fdbf3.js" defer="defer"></script>
<script src="/endlessq/assets/js/main.f841d8bb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/endlessq/"><div class="navbar__logo"><img src="/endlessq/img/logo-cropped.svg" alt="Endless Q" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/endlessq/img/logo-cropped.svg" alt="Endless Q" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">EndlessQ</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/endlessq/docs/quests">quests</a><a class="navbar__item navbar__link" href="/endlessq/about-me">about me</a></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_LcQY"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_juUc"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/endlessq/docs/quests">quests</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/endlessq/docs/vision-transformer/">Vision Transformers (ViT)</a><button aria-label="Collapse sidebar category &#x27;Vision Transformers (ViT)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/endlessq/docs/vision-transformer/model-structure">Model Structure</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/vit-model">The Main Class</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/masked-modeling">ViT for Masked Image Modeling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/pooling-classification-head">Pooling and Classification Heads</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/endlessq/docs/vision-transformer/sub-modules/">ViT Sub-Modules</a><button aria-label="Expand sidebar category &#x27;ViT Sub-Modules&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/endlessq/docs/vision-transformer/utils">Weight Initialization and Model Utilities</a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_CEj5"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/endlessq/docs/vision-transformer/"><span itemprop="name">Vision Transformers (ViT)</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Model Structure</span><meta itemprop="position" content="2"></li></ul></nav><div class="theme-doc-markdown markdown"><div class="one-column"><div><h1>Model Structure</h1>
<p>The Vision Transformer (ViT) model is an adaptation of the transformer architecture, originally designed for natural language processing, to computer vision.</p>
<p>In this section we&#x27;ll go over the underlying structure of ViT and how it is tailored for matrix inputs.</p>
<p>Transformers revolutionized the way sequential data is processed. Central to the transformer’s design is the self-attention mechanism, which allows the model to weigh the importance of different parts of the input sequence, whether they be words in a sentence or, as we’ll see with ViT, matrixes of pixels.</p>
<p>Adapting the transformer for image processing involves a conceptual leap in that it is treating an image not as a 2D array of pixels but as a sequence of flattened 2D patches.</p>
<p>These patches are analogous to words in a sentence. Each patch is linearly embedded (similar to word embeddings in NLP) and processed through the transformer network. This approach enables the model to consider the entire image context, breaking free from the local receptive fields of traditional CNNs.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-the-structure-the-vit-model">Understanding the Structure the ViT Model<a href="#understanding-the-structure-the-vit-model" class="hash-link" aria-label="Direct link to Understanding the Structure the ViT Model" title="Direct link to Understanding the Structure the ViT Model">​</a></h2>
<!-- -->
<ol>
<li>
<p>Input and Patch Embeddings: The first stage in ViT involves dividing the input image into fixed-size patches. These patches are then flattened and linearly transformed into embeddings, each serving as a token to be processed by the transformer. Additionally, a special classification token (CLS) is prepended to this sequence for tasks like image classification.</p>
</li>
<li>
<p>Positional Embeddings: Given transformers don’t inherently capture the order of input, positional embeddings are added to patch embeddings to provide spatial information. These embeddings are learned parameters and allow the model to understand the relative position of patches in the image.</p>
</li>
<li>
<p>Transformer Encoder: The core of ViT, the transformer encoder, consists of multiple layers, each comprising two sub-layers: a multi-head self-attention mechanism and a simple, position-wise fully connected feed-forward network. Normalization and residual connections are employed around each of these sub-layers.</p>
</li>
</ol>
<ul>
<li>
<p>Multi-Head Self-Attention: This mechanism allows the model to focus on different parts of the image, considering both local and global context simultaneously.</p>
</li>
<li>
<p>Feed-Forward Networks: These networks process the output from the attention mechanism. Each consists of two linear transformations with a non-linear activation in between.</p>
</li>
</ul>
<ol start="4">
<li>Output for Downstream Tasks: For classification tasks, the representation corresponding to the CLS token is passed through a final linear layer to produce logits for classification.</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-this-structure">Why This Structure?<a href="#why-this-structure" class="hash-link" aria-label="Direct link to Why This Structure?" title="Direct link to Why This Structure?">​</a></h2>
<p>By treating images as sequences, it can capture long-range dependencies across the entire image, something conventional CNNs struggle with.</p>
<p>The self-attention mechanism dynamically adapts to focus on relevant parts of the image, enhancing its capability for various tasks like image classification or object detection.</p>
<p>Furthermore, ViT can be pre-trained on large datasets and fine-tuned for specific tasks, a practice that has led to remarkable improvements in performance.</p></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/endlessq/docs/vision-transformer/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Vision Transformers (ViT)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/endlessq/docs/vision-transformer/vit-model"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">The Main Class</div></a></nav></div></div></div></div></main></div></div><div>Your screen is too small to view EndlessQ documentation. Please view on a larger device.</div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Sina Montazeri. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>